{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewVectorizer(object):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, dataset:pd.DataFrame, vectorizer:ReviewVectorizer):\n",
    "        self.dataset = dataset\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        train = dataset[dataset.split==\"train\"]\n",
    "        validation = dataset[dataset.split==\"val\"]\n",
    "        test = dataset[dataset.split==\"test\"]\n",
    "        \n",
    "        self._lookup_dict = {\n",
    "            \"train\": (train, len(train)),\n",
    "            \"validation\": (validation, len(validation)),\n",
    "            \"test\": (test, len(test))\n",
    "        }\n",
    "        \n",
    "        self.set_split(\"train\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls:ReviewDataset, dataset_path:str, vectorizer_path:str):\n",
    "        dataset = pd.read_csv(dataset_path)\n",
    "        vectorizer = self.load_vectorizer(vectorizer_path)\n",
    "        return cls(dataset, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer(vectorizer_path:str):\n",
    "        with open(vectorizer_path) as f:\n",
    "            return ReviewVectorizer.from_serializable(json.load(f))\n",
    "    \n",
    "    def save_vectorizer(self, vectorizer_path:str):\n",
    "        with open(vectorizer_path) as f:\n",
    "            json.dump(self._vectorizer.to_serializable(), f)\n",
    "            \n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_split(self, split:str=\"train\"):\n",
    "        self._target_split = split\n",
    "        self._target_data, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index:int):\n",
    "        row = self._target_data.iloc[index]\n",
    "        vector_review = self._vectorizer.vectorize(row.review)\n",
    "        index_rating = self._vectorizer.rating_vocab.lookup_token(row.rating)\n",
    "        return {\"x\":vector_review, \"y\":index_rating}\n",
    "    \n",
    "    def get_number_batches(self, batch_size:int):\n",
    "        return len(self) // batch_size\n",
    "    \n",
    "def generate_batches(dataset:pd.DataFrame, batch_size:int, shuffle:bool=True, drop_last:bool=True, device:str=\"cpu\"):\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
